{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257a51f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20d5a29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: bahasa_indonesia\n",
      "          username          language   work_id\n",
      "0   dianthus_peony  Bahasa Indonesia  36657928\n",
      "1        Reyan3779  Bahasa Indonesia  36657928\n",
      "2       CuddlyWorm  Bahasa Indonesia  36657928\n",
      "3  jinkook_married  Bahasa Indonesia  36657928\n",
      "4      agustDRkive  Bahasa Indonesia  36657928\n",
      "Language: português_brasileiro\n",
      "    username              language   work_id\n",
      "0   nic_ckie  Português brasileiro  35195854\n",
      "1   KimIsa15  Português brasileiro  32475397\n",
      "2  velezhard  Português brasileiro  32475397\n",
      "3   bunny445  Português brasileiro  32475397\n",
      "4    Lunnary  Português brasileiro  32475397\n",
      "Language: chinese\n",
      "            username language   work_id\n",
      "0           xiaowwai  chinese  40244955\n",
      "1         kwonorange  chinese  40244955\n",
      "2              EM_WX  chinese  40244955\n",
      "3  mintchocolatemint  chinese  40244955\n",
      "4      aaaaaaa_aaaaa  chinese  40244955\n",
      "Language: english\n",
      "        username language   work_id\n",
      "0      camote_24  english  39739578\n",
      "1       AdaoraKi  english  39739578\n",
      "2  enderwolf_438  english  39739578\n",
      "3      Jiggeukie  english  39739578\n",
      "4   purpleangel8  english  39739578\n",
      "Language: spain\n",
      "         username language   work_id\n",
      "0       Pentelho3    spain  38475859\n",
      "1  Dakaria_Scar05    spain  38475859\n",
      "2        sopemoon    spain  38475859\n",
      "3       l3ilaaart    spain  38475859\n",
      "4         AlphaTK    spain  38475859\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# 初始化一个空字典用于存储不同语言的DataFrame\n",
    "lits = {}\n",
    "\n",
    "# 遍历文件夹中的所有CSV文件\n",
    "for fn in sorted(glob.glob('/Users/josiechen/desktop/prepared data/*.csv')):\n",
    "    # 跳过不需要处理的文件\n",
    "    if 'anglo-norman' in fn:\n",
    "        continue\n",
    "    \n",
    "    # 读取CSV文件\n",
    "    df = pd.read_csv(fn)\n",
    "    \n",
    "    # 从文件名中提取语言名称，并转换为小写\n",
    "    lang = os.path.basename(fn).replace('prepared data_', '').replace('.csv', '').lower()\n",
    "    \n",
    "    # 将提取的'username', 'language', 'work_id'列存储到字典中\n",
    "    lits[lang] = df[['username', 'language', 'work_id']]\n",
    "\n",
    "# 输出结果检查\n",
    "for lang, data in lits.items():\n",
    "    print(f\"Language: {lang}\")\n",
    "    print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "619e8301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged and sorted data saved to /Users/josiechen/desktop/merged_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# 初始化一个空列表用于存储所有数据\n",
    "all_data = []\n",
    "\n",
    "# 遍历文件夹中的所有CSV文件\n",
    "for fn in sorted(glob.glob('/Users/josiechen/desktop/prepared data/*.csv')):\n",
    "    # 跳过不需要处理的文件\n",
    "    if 'anglo-norman' in fn:\n",
    "        continue\n",
    "    \n",
    "    # 读取CSV文件\n",
    "    df = pd.read_csv(fn)\n",
    "    \n",
    "    # 将读取的数据添加到列表中\n",
    "    all_data.append(df[['username', 'language', 'work_id']])\n",
    "\n",
    "# 将所有数据合并到一个DataFrame中\n",
    "combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# 按照username进行排序\n",
    "sorted_df = combined_df.sort_values(by='username')\n",
    "\n",
    "# 保存结果到新的CSV文件\n",
    "sorted_df.to_csv('/Users/josiechen/desktop/merged_data.csv', index=False)\n",
    "\n",
    "print(\"Merged and sorted data saved to /Users/josiechen/desktop/merged_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2b2d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#统计，有多少user可以读1门，2门，3门，4门，5门语言的文章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54ed4e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users who can read 1 language(s): 34566\n",
      "Number of users who can read 2 language(s): 1437\n",
      "Number of users who can read 3 language(s): 155\n",
      "Number of users who can read 4 language(s): 18\n",
      "Number of users who can read 5 language(s): 3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# 初始化一个空列表用于存储所有数据\n",
    "all_data = []\n",
    "\n",
    "# 遍历文件夹中的所有CSV文件\n",
    "for fn in sorted(glob.glob('/Users/josiechen/desktop/prepared data/*.csv')):\n",
    "    # 跳过不需要处理的文件\n",
    "    if 'anglo-norman' in fn:\n",
    "        continue\n",
    "    \n",
    "    # 读取CSV文件\n",
    "    df = pd.read_csv(fn)\n",
    "    \n",
    "    # 将读取的数据添加到列表中\n",
    "    all_data.append(df[['username', 'language', 'work_id']])\n",
    "\n",
    "# 将所有数据合并到一个DataFrame中\n",
    "combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# 统计每个用户可以阅读的不同语言数量\n",
    "user_lang_counts = combined_df.groupby('username')['language'].nunique()\n",
    "\n",
    "# 统计不同语言数量的用户数\n",
    "lang_reading_stats = user_lang_counts.value_counts().sort_index()\n",
    "\n",
    "# 输出结果\n",
    "for num_languages, num_users in lang_reading_stats.items():\n",
    "    print(f\"Number of users who can read {num_languages} language(s): {num_users}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00ce9a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users who can read 5 languages:\n",
      "No_Blon\n",
      "k0om4to\n",
      "zaurelie371986\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# 初始化一个空列表用于存储所有数据\n",
    "all_data = []\n",
    "\n",
    "# 遍历文件夹中的所有CSV文件\n",
    "for fn in sorted(glob.glob('/Users/josiechen/desktop/prepared data/*.csv')):\n",
    "    # 跳过不需要处理的文件\n",
    "    if 'anglo-norman' in fn:\n",
    "        continue\n",
    "    \n",
    "    # 读取CSV文件\n",
    "    df = pd.read_csv(fn)\n",
    "    \n",
    "    # 将读取的数据添加到列表中\n",
    "    all_data.append(df[['username', 'language', 'work_id']])\n",
    "\n",
    "# 将所有数据合并到一个DataFrame中\n",
    "combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# 统计每个用户可以阅读的不同语言数量\n",
    "user_lang_counts = combined_df.groupby('username')['language'].nunique()\n",
    "\n",
    "# 筛选出能够阅读5种语言的用户\n",
    "users_with_5_languages = user_lang_counts[user_lang_counts == 5].index\n",
    "\n",
    "# 输出能够阅读5种语言的用户列表\n",
    "print(\"Users who can read 5 languages:\")\n",
    "for user in users_with_5_languages:\n",
    "    print(user)\n",
    "\n",
    "# 如果需要将这些用户保存到文件中，可以使用以下代码：\n",
    "users_with_5_languages.to_series().to_csv('/Users/josiechen/desktop/users_with_5_languages.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0af320",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
